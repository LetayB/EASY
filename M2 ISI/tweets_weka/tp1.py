
# coding: utf-8

import os
import copy

SET_LOCAL_VAR1 = ""
SET_LOCAL_VAR2 = ""
SET_LOCAL_VAR3 = ""


#CLASSIFIERS = ["bayes.NaiveBayes","rules.OneR"]
CLASSIFIERS = ["trees.J48","bayes.NaiveBayes","rules.OneR"]

OUTPUT_FOLDER_NAME = "stats/"


OUTPUT_FILE_MODEL =  "model_NB"
OUPUT_FILE_STATS_TRAIN = "modele.stats"
OUTPUT_FILE_PRECISION =  "precision.prec"
OUTPUT_FILE_PREDICTION =  "prediction.pred"

TWEET_DATA_FILE_NAME = "tweet_data.arff"
TWEET_TRAIN_FILE_NAME = "tweet_train.arff"
TWEET_TEST_FILE_NAME = "tweet_test.arff"


TRAIN_DATA = TWEET_TRAIN_FILE_NAME
TEST_DATA = TWEET_TEST_FILE_NAME

TRAIN_DATA_WV = TRAIN_DATA.split('.')[0] + ".wv.arff"
TEST_DATA_WV = TEST_DATA.split('.')[0]+ ".wv.arff" 


ANNOTATIONS = ['+','-','=']


TRAIN_PERCENTAGE = 70

#os.system("java weka.classifiers.trees.J48 -t  -d model_NB")
#os.system("java weka.classifiers.trees.J48 -T chaman.arff -l model_NB -o -i")

def cn(string):
	s = copy.copy(string)
	s = s.replace(".","_") + "_"
	return s

def train(classifier,train_data):

	s = "java weka.classifiers." + classifier + " -t " + train_data + " -c 1 -no-cv -d " + OUTPUT_FOLDER_NAME +  cn(classifier) + OUTPUT_FILE_MODEL + " > " + OUTPUT_FOLDER_NAME + cn(classifier) + OUPUT_FILE_STATS_TRAIN
	print "Execute command => " + s
	os.system(s)

def eval_model(classifier,train_data) :
	s = "java weka.classifiers." + classifier + " -T " + train_data + " -c 1 -no-cv -l " + OUTPUT_FOLDER_NAME + cn(classifier) + OUTPUT_FILE_MODEL + " -o  > "  + OUTPUT_FOLDER_NAME + cn(classifier) + OUTPUT_FILE_PRECISION
	print "Execute command => " + s
	os.system(s)

def test_model(classifier,test_data) :
	s = "java weka.classifiers." + classifier + " -T " + test_data + " -c 1 -no-cv -l " + OUTPUT_FOLDER_NAME + cn(classifier) + OUTPUT_FILE_MODEL + " -p 0 > "  + OUTPUT_FOLDER_NAME + cn(classifier) + OUTPUT_FILE_PREDICTION 
	print "Execute command => " + s
	os.system(s)
	
def classify() :
	for x in CLASSIFIERS :
		train(x,TRAIN_DATA_WV)
		eval_model(x,TRAIN_DATA_WV)
		test_model(x,TEST_DATA_WV)

def getHeaderAnnotation() :
	s = "{"
	s = s + ANNOTATIONS[0]
	for n in range(1,len(ANNOTATIONS)):
		s = s + ',' + ANNOTATIONS[n]
	s = s + "}"
	return s

def stringToWordVector() :
	s = "java weka.filters.unsupervised.attribute.StringToWordVector -b -i "+ TRAIN_DATA + " -o " + TRAIN_DATA_WV + " -r "+ TEST_DATA +" -s "+ TEST_DATA_WV
	os.system(s)


#---------------------------------------------#



PATH = "/info/projets/fouilles_donnees_m2/deft/"


def print_header():
	s = "@relation corpus_tweets_t1 \n@attribute text string \n@attribute polarity " + getHeaderAnnotation() + "\n@data\n"
	return s


TWEET_DATA = open(TWEET_DATA_FILE_NAME,"w+")
#TWEET_DATA.write(print_header("{+,-,=}"))


#for file in os.listdir(PATH+"Train_References"):
#    if file.endswith(".txt"):
#        open(file)



lines_number = 0
 
a = []
with open(PATH+"Train_References/"+"T1.txt", "r") as f:
	for l in f:
		a = l.split("\t")
		fname = PATH+"Train_Data/"+a[0]+".txt"
		if(os.path.isfile(fname)) :
			temp_f = open(fname,"r")
			s = '"'+temp_f.read().replace('"','')[:-1] +'", '+a[1]  # : is the strips operator and allows use to remove the carriage generated by the end of the file
    		TWEET_DATA.write(s)
    		lines_number += 1

f.close()
TWEET_DATA.close()


TWEET_TRAIN = open(TWEET_TRAIN_FILE_NAME, "w+")
TWEET_TEST = open(TWEET_TEST_FILE_NAME, "w+")

TWEET_TRAIN.write(print_header())
TWEET_TEST.write(print_header())

matrix_split_annot_train = {key: 0 for key in ANNOTATIONS}
matrix_split_annot_test = {key: 0 for key in ANNOTATIONS}

lines_limit_train =  ( lines_number * TRAIN_PERCENTAGE ) / 100

with open(TWEET_DATA_FILE_NAME, "r+") as TWEET_DATA:
	lines = TWEET_DATA.readlines()
	for i in range(lines_limit_train):
		matrix_split_annot_train[lines[i][-2:-1]] += 1
		TWEET_TRAIN.write(lines[i])
	for i in range(lines_limit_train,lines_number):
		matrix_split_annot_test[lines[i][-2:-1]] += 1
		TWEET_TEST.write(lines[i])




TWEET_TRAIN.close()
TWEET_TEST.close()
TWEET_DATA.close()

print "Train data :"
print matrix_split_annot_train

print "Test data :"
print matrix_split_annot_test


stringToWordVector()

classify()



